<h1> Welcome to Ochadai "Physical Behavior Assessment Lab" </h1>

<p> We are evaluating physical activity in various populations using wearable activity trackers. We are also developping new hardware and software methods for the measurement of physical behaviours. For example, machine learning techniques are employed to develop algorithms capable of recognizing physical behaviors using data collected from wearable devices.</p>
<p> Our research goals are:
<ol>
<li>to understand the relationship between physical activity, health and well-being in various populations.</li>
<li>to develop new technologies to support more accurate measurements of physical behaviors.</li>
<li>to promote physical activty as a primary component of a sustainable society.</li>
</ol></p>

<h2 id="Selected articles">Selected articles</h2>

<img align="left" src="img.jpg">
>Nakajima Y, Kitayama A, et al. Objective Assessment of Physical Activity at Home Using a Novel Floor-Vibration Monitoring System: Validation and Comparison With Wearable Activity Trackers and Indirect Calorimetry Measurements. JMIR Form Res. 2024;8:e51874. Published 2024 Apr 25. doi:10.2196/51874

<strong>Objective Assessment of Physical Activity at Home Using a Novel Floor-Vibration Monitoring System: Validation and Comparison With Wearable Activity Trackers and Indirect Calorimetry Measurements (JMIR Formative Research, 2024)</strong>
<a class="tag" href="https://doi.org/10.2196/51874">DOI</a>
<a class="tag" href="https://formative.jmir.org/2024/1/e51874">URL</a>
<a class="tag" href="https://formative.jmir.org/2024/1/e51874/PDF">PDF</a>
This study evaluated the feasibility of estimating physical activity through floor vibration monitoring. Accelerometer sensors were installed in a smart home floor to capture vibration data from 10 participants during four activities. Energy expenditure was measured via indirect calorimetry, and Actigraph trackers were used to estimate both energy expenditure and step count. Models based on features extracted from floor vibrations outperformed Actigraph trackers in estimating both metrics.</p>

<p><strong>Random forest algorithms to classify frailty and falling history in seniors using plantar pressure measurement insoles: a large-scale
feasibility study (BMC Geriatrics, 2022)</strong>
<a class="tag" href="https://doi.org/10.1186/s12877-022-03425-5">DOI</a>
<a class="tag" href="https://bmcgeriatr.biomedcentral.com/articles/10.1186/s12877-022-03425-5">URL</a>
<a class="tag" href="Articles/s12877-022-03425-5.pdf">PDF</a>
This study proposes an objective method to complement existing tools for identifying frailty in seniors. Seven hundred twelve senior participantscompleted a balance test and walking trial, with plantar pressure data collected via 7-sensor insoles. Frailty, assessed using the Kihon Checklist, was classified with 75% accuracy using random forest algorithms on 184 extracted features. These findings suggest smart insoles could help clinicians in early frailty detection.</p>

<p><strong>Random forest algorithms for recognizing daily life activities using plantar pressure information: a smart-shoe study (PeerJ, 2020)</strong>
<a class="tag" href="https://doi.org/10.7717/peerj.10170">DOI</a>
<a class="tag" href="https://peerj.com/articles/10170/">URL</a>
<a class="tag" href="Articles/peerj-10170.pdf">PDF</a>
<a class="tag" href="https://zenodo.org/records/4050390">DATA</a>
<a class="tag" href="https://zenodo.org/records/4050390">CODE</a>
This study developed an algorithm to recognize activities using plantar pressure data from smart shoes. Seventeen participants performed nine sedentary and locomotive activities, and random forest models processed the data. A 20-second window length achieved 89% accuracy. "Running" showed 100% sensitivity, while "walking up a slope" had the lowest (63%). Minimal sensor setups (2-3 sensors) still performed well. Smart shoes could help assess daily activities.</p>

<p><a href="https://formative.jmir.org/2024/1/e51874/PDF"><img src="images/formative-2024-1-e51874-fig-1.jpg" alt="" class="border small" /></a>
<a href="Articles/s12877-022-03425-5.pdf"><img src="images/s12877-022-03425-5-fig-3.png" alt="" class="border small" /></a>
<a href="Articles/peerj-10170.pdf"><img src="images/peerj-10170-fig-1.jpg" alt="" class="border small" /></a></p>




Sharing code and data from the [Physical Behavior Assessment Laboratory](http://www.eng.ocha.ac.jp/Tripette_Site/home.html) (PI: [Julien TRIPETTE](http://www.eng.ocha.ac.jp/Tripette_Site/j-trip.html)) at the [Faculty of Life Science, Department of Human and Environmental Sciences](https://www.hles.ocha.ac.jp/ug/eng/index.html), [Ochanomizu University](https://www.ocha.ac.jp/index.html): physical activity, machine learning, neuroinformatics.  
For any questions, [send me an email](tripette.julien@ocha.ac.jp)
